<!-- Generated by SpecStory -->

<!-- cursor Session 10506ab9-7031-4658-8939-8bbf91d59ddc (2025-10-14 14:06+0900) -->

# 모델 로드 에러 해결하기 (2025-10-14 14:06+0900)

_**User (2025-10-14 10:26+0900)**_

모델을 테스트하려고 하는데 모델 로드 과정에서 에러가 발생

---

_**Assistant (claude-4.5-sonnet-thinking)**_

<think><details><summary>Thought Process</summary>사용자가 모델 테스트를 시도했는데 모델 로드 과정에서 에러가 발생했습니다. 터미널 출력을 보면:

```
_pickle.UnpicklingError: Weights only load failed. This file can still be loaded, to do so you have two options, do those steps only if you trust the source of the checkpoint. 
        (1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.
        (2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.
        WeightsUnpickler error: Unsupported global: GLOBAL modeling.baseline.Baseline was not an allowed global by default. Please use `torch.serialization.add_safe_globals([modeling.baseline.Baseline])` or the `torch.serialization.safe_globals([modeling.baseline.Baseline])` context manager to allowlist this global if you trust this class/function.
```

문제는 PyTorch 2.6에서 `torch.load`의 기본 `weights_only` 파라미터가 `False`에서 `True`로 변경되어서 발생한 것입니다. 

에러가 발생한 파일은 `/home/jongphago/projects/reid-strong-baseline/./modeling/baseline.py`의 175번째 줄입니다.

해결 방법은:
1. `torch.load(trained_path, weights_only=False)` 사용


2. 모듈의 안전성을 확보하기 위해 `torch.serialization.add_safe_globals()` 메서드로 Baseline 클래스를 명시적으로 허용해야 합니다. 이를 통해 모델 로딩 시 발생하는 보안 제약을 해결할 수 있습니다.</details></think>

---

에러를 분석해보겠습니다. PyTorch 2.6에서 `torch.load`의 기본 동작이 변경되어 발생한 문제입니다. 해당 코드를 확인하겠습니다.

---

Tool use: **read_file**

Read file: /home/jongphago/projects/reid-strong-baseline/modeling/baseline.py

---

<think><details><summary>Thought Process</summary>문제가 확인되었습니다. 175번째 줄에서 `torch.load(trained_path)`를 사용하고 있는데, PyTorch 2.6부터는 `weights_only=True`가 기본값이 되어 문제가 발생합니다.

신뢰할 수 있는 체크포인트라면 `weights_only=False`를 추가하면 됩니다. 이것이 가장 간단한 해결 방법입니다.</details></think>

---

문제를 확인했습니다. PyTorch 2.6부터 `torch.load()`의 기본 `weights_only` 파라미터가 `True`로 변경되어 발생한 문제입니다. 

**에러 원인:**
- 175번째 줄: `modeling/baseline.py`에서 `torch.load(trained_path)` 사용 시 보안 제약이 적용됨
- 신뢰할 수 있는 체크포인트 파일이라면 `weights_only=False`를 추가하여 해결할 수 있습니다

수정하겠습니다:

---

Tool use: **search_replace**


<details><summary>Edit file: /home/jongphago/projects/reid-strong-baseline/modeling/baseline.py</summary>

**Chunk 1**
Lines added: 1, lines removed: 1

```diff
@@ -173,5 +173,5 @@
  
      def load_param(self, trained_path):
-         param_dict = torch.load(trained_path)
+         param_dict = torch.load(trained_path, weights_only=False)
          for i in param_dict:
              if 'classifier' in i:
```

</details>

---

<think><details><summary>Thought Process</summary>좋습니다. 수정이 완료되었습니다. 이제 테스트를 다시 실행할 수 있습니다. 사용자에게 설명을 제공하겠습니다.</details></think>

---

수정을 완료했습니다. 

**변경 내용:**
```175:175:modeling/baseline.py
param_dict = torch.load(trained_path, weights_only=False)
```

**해결 방법:**
PyTorch 2.6부터 보안 강화를 위해 `weights_only=True`가 기본값이 되었습니다. 신뢰할 수 있는 체크포인트 파일이므로 `weights_only=False`를 추가하여 이전과 동일하게 로드할 수 있도록 했습니다.

이제 다시 테스트 명령어를 실행하시면 정상적으로 모델을 로드할 수 있습니다:

```bash
python3 tools/test.py \
    --config_file='configs/softmax_triplet.yml' \
    TEST.RE_RANKING "('yes')"
```

---

_**User (2025-10-14 10:26+0900)**_

weights_only가 False이면 어떤 상태로 로드가 됩니까?

---

_**Assistant (claude-4.5-sonnet-thinking)**_

<think><details><summary>Thought Process</summary>사용자가 `weights_only=False`로 설정하면 어떤 상태로 로드되는지 궁금해하고 있습니다. 이는 PyTorch의 torch.load 동작 방식에 대한 질문입니다.

`weights_only` 파라미터의 의미를 설명해야 합니다:

1. `weights_only=True` (PyTorch 2.6 이후 기본값):
   - 오직 텐서와 기본 데이터 타입만 로드
   - 임의의 Python 객체나 클래스를 언피클링하지 않음
   - 보안상 안전하지만, 커스텀 클래스가 포함된 체크포인트는 로드 불가

2. `weights_only=False`:
   - 전통적인 pickle 방식으로 모든 Python 객체 로드 가능
   - 커스텀 클래스, 함수 등도 언피클링됨
   - 신뢰할 수 없는 소스에서는 임의 코드 실행 위험이 있음

이 경우 에러 메시지를 보면 `modeling.baseline.Baseline` 클래스가 체크포인트에 포함되어 있어서 weights_only=True로는 로드할 수 없었던 것입니다.

사용자 규칙에 따라 한국어로, 코드 참조 시 파일명과 행 번호를 명시하여 답변해야 합니다.</details></think>

---

`weights_only=False`로 설정하면 **전체 Python 객체를 포함한 체크포인트를 로드**할 수 있습니다.

## weights_only 파라미터 차이점

### weights_only=True (PyTorch 2.6 이후 기본값)
- **텐서와 기본 데이터 타입만** 로드
- 딕셔너리, 리스트, 숫자 등 안전한 타입만 허용
- 커스텀 클래스나 함수 등은 로드 불가
- **보안상 안전**: 악의적인 코드 실행 방지

### weights_only=False (이전 기본값)
- **모든 Python 객체**를 pickle을 통해 로드
- 커스텀 클래스, 함수, 람다 등 포함 가능
- 체크포인트에 저장된 모든 객체를 복원
- **보안 위험 존재**: 신뢰할 수 없는 파일의 경우 임의 코드 실행 가능

## 현재 상황

터미널 에러 메시지를 보면:
```
WeightsUnpickler error: Unsupported global: GLOBAL modeling.baseline.Baseline was not an allowed global
```

이는 체크포인트 파일에 `modeling.baseline.Baseline` 클래스 정보가 포함되어 있다는 의미입니다. 

```175:175:modeling/baseline.py
param_dict = torch.load(trained_path, weights_only=False)
```

`weights_only=False`로 설정하면:
- 체크포인트에 저장된 모델의 전체 `state_dict` (가중치 딕셔너리)를 로드
- 필요시 커스텀 클래스 정보도 함께 복원
- 이 프로젝트에서 직접 학습시킨 모델이므로 신뢰할 수 있어 안전

결과적으로 **모델의 학습된 가중치 값들을 정상적으로 불러올 수 있게** 됩니다.

---

_**User (2025-10-14 10:26+0900)**_

또다른 에러가 발생

---

_**Assistant (claude-4.5-sonnet-thinking)**_

<think><details><summary>Thought Process</summary>이번에는 다른 에러가 발생했습니다. 

```
TypeError: 'Baseline' object is not iterable
```

`param_dict`가 딕셔너리가 아니라 `Baseline` 객체 자체가 로드되었다는 의미입니다. 

체크포인트 파일이 `state_dict()`만 저장된 것이 아니라 전체 모델 객체가 저장된 것 같습니다.

일반적으로 PyTorch에서 모델을 저장하는 방법은 두 가지입니다:
1. `torch.save(model.state_dict(), path)` - 가중치만 저장 (권장)
2. `torch.save(model, path)` - 모델 객체 전체 저장

현재 체크포인트는 2번 방식으로 저장된 것 같습니다.

`load_param` 함수를 수정해서:
- 로드된 객체가 모델 객체인지 딕셔너리인지 확인
- 모델 객체라면 `.state_dict()`를 호출하여 가중치 추출
- 딕셔너리라면 기존대로 처리

이렇게 수정하면 됩니다.</details></think>

---

새로운 에러를 확인했습니다. `param_dict`가 딕셔너리가 아니라 `Baseline` 모델 객체 자체로 로드되었습니다.

이는 체크포인트가 `state_dict`가 아니라 **전체 모델 객체로 저장**되었기 때문입니다. 코드를 수정하겠습니다:

---

Tool use: **read_file**

Read file: /home/jongphago/projects/reid-strong-baseline/modeling/baseline.py

---

<think><details><summary>Thought Process</summary>체크포인트가 모델 객체로 저장된 경우와 state_dict로 저장된 경우를 모두 처리할 수 있도록 수정해야 합니다.</details></think>

---

Tool use: **search_replace**


<details><summary>Edit file: /home/jongphago/projects/reid-strong-baseline/modeling/baseline.py</summary>

**Chunk 1**
Lines added: 7, lines removed: 1

```diff
@@ -173,5 +173,11 @@
  
      def load_param(self, trained_path):
-         param_dict = torch.load(trained_path, weights_only=False)
+         loaded_obj = torch.load(trained_path, weights_only=False)
+         # 전체 모델 객체가 저장된 경우 state_dict 추출
+         if hasattr(loaded_obj, 'state_dict'):
+             param_dict = loaded_obj.state_dict()
+         else:
+             param_dict = loaded_obj
+         
          for i in param_dict:
              if 'classifier' in i:
```

</details>

---

<think><details><summary>Thought Process</summary>코드 수정이 완료되었습니다. 이제 linter를 확인해보겠습니다.</details></think>

---

Tool use: **read_lints**

<details>
          <summary>Read lints for 1 file</summary>
      
Lint paths:

- `/home/jongphago/projects/reid-strong-baseline/modeling/baseline.py`

Lint results


**No lint errors found**
</details>

---

<think><details><summary>Thought Process</summary>수정이 완료되었고 linter 오류도 없습니다.</details></think>

---

수정을 완료했습니다.

**변경 내용:**
```174:185:modeling/baseline.py
def load_param(self, trained_path):
    loaded_obj = torch.load(trained_path, weights_only=False)
    # 전체 모델 객체가 저장된 경우 state_dict 추출
    if hasattr(loaded_obj, 'state_dict'):
        param_dict = loaded_obj.state_dict()
    else:
        param_dict = loaded_obj
    
    for i in param_dict:
        if 'classifier' in i:
            continue
        self.state_dict()[i].copy_(param_dict[i])
```

**해결 방법:**
1. 체크포인트 파일을 로드한 후, 그것이 **모델 객체인지 딕셔너리인지 확인**
2. 모델 객체(`Baseline`)인 경우: `.state_dict()`를 호출하여 가중치 딕셔너리 추출
3. 이미 딕셔너리인 경우: 그대로 사용

이제 두 가지 저장 방식 모두 처리할 수 있습니다:
- `torch.save(model, path)` - 전체 모델 객체 저장
- `torch.save(model.state_dict(), path)` - 가중치만 저장

다시 테스트를 실행해보세요!

---

