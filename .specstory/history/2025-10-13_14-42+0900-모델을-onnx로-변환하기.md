<!-- Generated by SpecStory -->

<!-- cursor Session 41666a00-379c-4a32-8b63-e2c135a0d5b7 (2025-10-13 14:42+0900) -->

# 모델을 onnx로 변환하기 (2025-10-13 14:42+0900)

_**User (2025-10-13 10:14+0900)**_

학습한 모델을 onnx 확장자로 변환하고 싶습니다. 

---

_**Assistant (claude-4.5-sonnet-thinking)**_

<think><details><summary>Thought Process</summary>사용자가 학습한 모델을 ONNX 형식으로 변환하고 싶어합니다. 이를 위해서는 먼저 몇 가지 정보가 필요합니다:

1. 어떤 모델을 변환할 것인지 (학습된 모델의 경로)
2. 모델의 구조 (입력 크기 등)
3. 현재 프로젝트의 구조 파악

사용자 규칙에 따르면, 질문을 받은 경우 답변을 하기 위해 추가 정보가 필요한 경우 하나씩 요청해야 합니다. 충분한 대화를 통해 질문의 답변을 위한 정보를 수집해야 합니다.

먼저 프로젝트 구조를 파악하고, 모델 변환을 위해 필요한 정보를 수집해야 할 것 같습니다.

필요한 정보:
1. 학습된 모델 파일의 경로
2. 모델의 입력 크기 (config 파일을 보면 [256, 128]인 것으로 보임)
3. 모델 구조 파악 (build_model 함수 확인)

먼저 modeling 디렉토리를 확인하여 모델 구조를 파악하고, 그 다음 사용자에게 필요한 정보를 질문하겠습니다.</details></think>

---

학습한 모델을 ONNX로 변환하는 것을 도와드리겠습니다. 

먼저 몇 가지 정보가 필요합니다. 질문에 답변해 주시겠습니까?

1. **변환하려는 학습된 모델 파일의 경로**는 어디에 있나요?
   - 예: `./log/gu/reid_baseline_review/.../model_120.pth`

2. **변환 후 저장할 ONNX 파일의 경로**를 어디로 하시겠습니까?

먼저 프로젝트의 모델 구조를 확인하겠습니다.

---

Tool use: **codebase_search**

<details>
                <summary>Searched codebase "Where is build_model function defined and how does it create the model?" • **14** results</summary>
            
| File | Lines |
|------|-------|
| `modeling/__init__.py` | L13 |
| `modeling/baseline.py` | L29-178 |
| `tools/train.py` | L115 |
| `config/defaults.py` | L51 |
| `solver/build.py` | L43 |
| `modeling/baseline.py` | L34-178 |
| `modeling/baseline.py` | L34 |
| `modeling/backbones/resnet.py` | L50-148 |
| `data/build.py` | L44 |
| `solver/build.py` | L9-43 |
| `layers/__init__.py` | L89 |
| `tools/test.py` | L66 |
| `data/transforms/build.py` | L30 |
| `engine/trainer.py` | L96 |

</details>

---

Tool use: **list_dir**

<details>
            <summary>Listed directory undefined • **0** results</summary>
        
No results found
</details>

---

<think><details><summary>Thought Process</summary>좋습니다. 프로젝트 구조를 파악했고, 학습된 모델 파일들이 다음 경로에 있는 것을 확인했습니다:
- `/home/jongphago/projects/reid-strong-baseline/log/gu/reid_baseline_review/Opensource_test/market1501/Experiment-all-tricks-256x128-bs16x4-warmup10-erase0_5-labelsmooth_on-laststride1-bnneck_on/resnet50_model_120.pth`

config 파일을 보면 입력 크기는 [256, 128]입니다.

이제 사용자에게 필요한 정보를 확인하고 ONNX 변환 스크립트를 작성하거나 실행해줘야 합니다.</details></think>

---

좋습니다! 학습된 모델 파일들이 다음 경로에 있는 것을 확인했습니다:
- `resnet50_model_120.pth` (120 에폭)
- `resnet50_model_80.pth` (80 에폭)  
- `resnet50_model_40.pth` (40 에폭)

다음 정보를 확인해 주세요:

1. **어떤 모델을 변환하시겠습니까?**
   - 120 에폭 모델? (resnet50_model_120.pth)
   - 다른 모델?

2. **변환된 ONNX 파일을 어디에 저장하시겠습니까?**
   - 같은 디렉토리에 저장? (예: `resnet50_model_120.onnx`)
   - 다른 경로?

3. **ONNX 변환 스크립트를 만들어 드릴까요, 아니면 바로 변환을 실행할까요?**

참고로 config 파일에서 입력 이미지 크기는 `[256, 128]` (높이 x 너비)로 설정되어 있습니다.

---

_**User (2025-10-13 10:14+0900)**_

1. 120에포크 모델입니다. 
2.
@export/ 이 경로에 저장합니다. 
3. 변환 스크립트 생성후 실행하시오. 

---

_**Assistant (claude-4.5-sonnet-thinking)**_

<think><details><summary>Thought Process</summary>사용자가 다음을 요청했습니다:
1. 120 에폭 모델을 변환
2. @export/ 경로에 저장 (프로젝트 루트에 export 폴더)
3. 변환 스크립트 생성 후 실행

ONNX 변환을 위해서는:
1. 모델 구조를 파악해야 함
2. 적절한 입력 텐서 크기 설정
3. torch.onnx.export 사용

먼저 modeling/baseline.py를 읽어서 전체 모델 구조를 파악하고, ONNX 변환 스크립트를 작성해야 합니다.</details></think>

---

알겠습니다. 120 에폭 모델을 ONNX로 변환하는 스크립트를 생성하고 실행하겠습니다.

먼저 모델 구조를 확인한 후 변환 스크립트를 작성하겠습니다.

---

Tool use: **read_file**

Read file: /home/jongphago/projects/reid-strong-baseline/modeling/baseline.py

---

Tool use: **read_file**

Read file: /home/jongphago/projects/reid-strong-baseline/config/defaults.py

---

<think><details><summary>Thought Process</summary>좋습니다. 모델 구조를 파악했습니다:
- Baseline 모델은 ResNet50 백본 사용
- BNNeck 사용 (config에서 확인)
- 입력 크기: [256, 128] (height, width)
- inference 시에는 feat를 반환 (neck_feat가 'after'이면 bottleneck 이후의 feature)

이제 ONNX 변환 스크립트를 작성하겠습니다. Market1501 데이터셋의 클래스 수도 알아야 합니다.</details></think>

---

Tool use: **codebase_search**

<details>
                <summary>Searched codebase "How many classes does Market1501 dataset have?" • **15** results</summary>
            
| File | Lines |
|------|-------|
| `data/datasets/market1501.py` | L84 |
| `data/datasets/market1501.py` | L9-84 |
| `data/datasets/__init__.py` | L28 |
| `data/datasets/msmt17.py` | L82 |
| `data/datasets/bases.py` | L62 |
| `data/datasets/msmt17.py` | L11-82 |
| `data/build.py` | L44 |
| `data/datasets/dukemtmcreid.py` | L105 |
| `data/datasets/veri.py` | L81 |
| `data/datasets/bases.py` | L45-94 |
| `data/datasets/bases.py` | L9-94 |
| `data/datasets/veri.py` | L3-81 |
| `data/datasets/cuhk03.py` | L12-258 |
| `data/datasets/dukemtmcreid.py` | L14-105 |
| `data/datasets/cuhk03.py` | L258 |

</details>

---

<think><details><summary>Thought Process</summary>Market1501의 주석에 보면 "# identities: 1501 (+1 for background)"라고 되어 있습니다. 하지만 실제로 학습시 relabel=True로 처리하므로, num_classes는 실제 학습 데이터에 있는 클래스 수로 결정됩니다.

log 파일을 확인해서 정확한 클래스 수를 알아볼 수 있습니다. 또는 모델 파일을 로드해서 classifier의 output dimension을 확인할 수 있습니다.

일단 ONNX 변환 스크립트를 작성하겠습니다. 스크립트에서는 모델을 로드한 후 자동으로 클래스 수를 추론하도록 하겠습니다.</details></think>

---

이제 ONNX 변환 스크립트를 작성하겠습니다.

---

Tool use: **write**


<details><summary>Edit file: /home/jongphago/projects/reid-strong-baseline/tools/convert_to_onnx.py</summary>

**Chunk 1**
Lines added: 149, lines removed: 1

```diff
@@ -1,1 +1,149 @@
- 
+ # encoding: utf-8
+ """
+ ONNX 변환 스크립트
+ 학습된 PyTorch 모델을 ONNX 형식으로 변환합니다.
+ """
+ 
+ import argparse
+ import os
+ import sys
+ import torch
+ 
+ sys.path.append('.')
+ from config import cfg
+ from modeling import build_model
+ 
+ 
+ def convert_to_onnx(cfg, model_path, output_path, input_size):
+     """
+     PyTorch 모델을 ONNX로 변환
+     
+     Args:
+         cfg: 설정 객체
+         model_path: 학습된 모델 파일 경로 (.pth)
+         output_path: 출력할 ONNX 파일 경로 (.onnx)
+         input_size: 입력 이미지 크기 (height, width)
+     """
+     
+     # 모델 파일 로드하여 클래스 수 추정
+     print(f"모델 파일 로드 중: {model_path}")
+     state_dict = torch.load(model_path, map_location='cpu')
+     
+     # classifier의 weight shape에서 클래스 수 추정
+     # classifier.weight의 shape는 [num_classes, feature_dim]
+     num_classes = None
+     for key in state_dict.keys():
+         if 'classifier.weight' in key:
+             num_classes = state_dict[key].shape[0]
+             print(f"감지된 클래스 수: {num_classes}")
+             break
+     
+     if num_classes is None:
+         raise ValueError("모델에서 클래스 수를 찾을 수 없습니다.")
+     
+     # 모델 생성
+     print("모델 구조 생성 중...")
+     model = build_model(cfg, num_classes)
+     
+     # 학습된 가중치 로드
+     model.load_state_dict(state_dict)
+     
+     # evaluation 모드로 설정
+     model.eval()
+     
+     # 더미 입력 생성 (batch_size=1, channels=3, height, width)
+     height, width = input_size
+     dummy_input = torch.randn(1, 3, height, width)
+     
+     print(f"입력 크기: {dummy_input.shape}")
+     print("ONNX 변환 시작...")
+     
+     # ONNX로 변환
+     torch.onnx.export(
+         model,                      # 변환할 모델
+         dummy_input,                # 더미 입력
+         output_path,                # 출력 파일 경로
+         export_params=True,         # 학습된 파라미터도 저장
+         opset_version=11,           # ONNX 버전
+         do_constant_folding=True,   # 최적화
+         input_names=['input'],      # 입력 이름
+         output_names=['output'],    # 출력 이름
+         dynamic_axes={              # 동적 배치 크기 지원
+             'input': {0: 'batch_size'},
+             'output': {0: 'batch_size'}
+         }
+     )
+     
+     print(f"✓ ONNX 변환 완료: {output_path}")
+     
+     # 변환된 파일 정보 출력
+     file_size = os.path.getsize(output_path) / (1024 * 1024)  # MB 단위
+     print(f"파일 크기: {file_size:.2f} MB")
+ 
+ 
+ def main():
+     parser = argparse.ArgumentParser(description="ReID 모델을 ONNX로 변환")
+     parser.add_argument(
+         "--config_file", 
+         default="configs/softmax_triplet.yml", 
+         help="설정 파일 경로", 
+         type=str
+     )
+     parser.add_argument(
+         "--model_path",
+         required=True,
+         help="변환할 모델 파일 경로 (.pth)",
+         type=str
+     )
+     parser.add_argument(
+         "--output_path",
+         required=True,
+         help="출력 ONNX 파일 경로",
+         type=str
+     )
+     parser.add_argument(
+         "opts", 
+         help="명령줄을 통한 설정 옵션 수정", 
+         default=None,
+         nargs=argparse.REMAINDER
+     )
+     
+     args = parser.parse_args()
+     
+     # 설정 로드
+     if args.config_file != "":
+         cfg.merge_from_file(args.config_file)
+     cfg.merge_from_list(args.opts)
+     cfg.freeze()
+     
+     print("=" * 60)
+     print("ONNX 변환 설정:")
+     print(f"  설정 파일: {args.config_file}")
+     print(f"  모델 파일: {args.model_path}")
+     print(f"  출력 경로: {args.output_path}")
+     print(f"  입력 크기: {cfg.INPUT.SIZE_TEST}")
+     print(f"  모델 이름: {cfg.MODEL.NAME}")
+     print(f"  Neck: {cfg.MODEL.NECK}")
+     print(f"  Neck Feat: {cfg.TEST.NECK_FEAT}")
+     print("=" * 60)
+     
+     # 출력 디렉토리 생성
+     output_dir = os.path.dirname(args.output_path)
+     if output_dir and not os.path.exists(output_dir):
+         os.makedirs(output_dir)
+         print(f"출력 디렉토리 생성: {output_dir}")
+     
+     # 변환 실행
+     convert_to_onnx(
+         cfg=cfg,
+         model_path=args.model_path,
+         output_path=args.output_path,
+         input_size=cfg.INPUT.SIZE_TEST
+     )
+     
+     print("\n변환이 성공적으로 완료되었습니다!")
+ 
+ 
+ if __name__ == '__main__':
+     main()
+ 
```

</details>

---

<think><details><summary>Thought Process</summary>ONNX 변환 스크립트를 생성했습니다. 이제 export 디렉토리를 만들고 스크립트를 실행해야 합니다.</details></think>

---

이제 스크립트를 실행하겠습니다.

---

Tool use: **run_terminal_cmd**

```bash
cd /home/jongphago/projects/reid-strong-baseline && mkdir -p export
```

---

<think><details><summary>Thought Process</summary>이제 변환 스크립트를 실행합니다. 모델 경로와 출력 경로를 지정해야 합니다.</details></think>

---

Tool use: **run_terminal_cmd**

```bash
cd /home/jongphago/projects/reid-strong-baseline && python tools/convert_to_onnx.py --config_file configs/softmax_triplet.yml --model_path log/gu/reid_baseline_review/Opensource_test/market1501/Experiment-all-tricks-256x128-bs16x4-warmup10-erase0_5-labelsmooth_on-laststride1-bnneck_on/resnet50_model_120.pth --output_path export/resnet50_model_120.onnx
```

```
Command 'python' not found, did you mean:
  command 'python3' from deb python3
  command 'python' from deb python-is-python3

```

---

<think><details><summary>Thought Process</summary>python 명령어가 없으니 python3를 사용해야 합니다.</details></think>

---

Tool use: **run_terminal_cmd**

```bash
cd /home/jongphago/projects/reid-strong-baseline && python3 tools/convert_to_onnx.py --config_file configs/softmax_triplet.yml --model_path log/gu/reid_baseline_review/Opensource_test/market1501/Experiment-all-tricks-256x128-bs16x4-warmup10-erase0_5-labelsmooth_on-laststride1-bnneck_on/resnet50_model_120.pth --output_path export/resnet50_model_120.onnx
```

```

A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.6 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/jongphago/projects/reid-strong-baseline/tools/convert_to_onnx.py", line 148, in <module>
    main()
  File "/home/jongphago/projects/reid-strong-baseline/tools/convert_to_onnx.py", line 137, in main
    convert_to_onnx(
  File "/home/jongphago/projects/reid-strong-baseline/tools/convert_to_onnx.py", line 30, in convert_to_onnx
    state_dict = torch.load(model_path, map_location='cpu')
  File "/home/jongphago/.local/lib/python3.10/site-packages/torch/serialization.py", line 789, in load
    return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
  File "/home/jongphago/.local/lib/python3.10/site-packages/torch/serialization.py", line 1131, in _load
    result = unpickler.load()
  File "/home/jongphago/.local/lib/python3.10/site-packages/torch/_utils.py", line 153, in _rebuild_tensor_v2
    tensor = _rebuild_tensor(storage, storage_offset, size, stride)
  File "/home/jongphago/.local/lib/python3.10/site-packages/torch/_utils.py", line 146, in _rebuild_tensor
    t = torch.tensor([], dtype=storage.dtype, device=storage.untyped().device)
/home/jongphago/.local/lib/python3.10/site-packages/torch/_utils.py:146: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:77.)
  t = torch.tensor([], dtype=storage.dtype, device=storage.untyped().device)
============================================================
ONNX 변환 설정:
  설정 파일: configs/softmax_triplet.yml
  모델 파일: log/gu/reid_baseline_review/Opensource_test/market1501/Experiment-all-tricks-256x128-bs16x4-warmup10-erase0_5-labelsmooth_on-laststride1-bnneck_on/resnet50_model_120.pth
  출력 경로: export/resnet50_model_120.onnx
  입력 크기: [256, 128]
  모델 이름: resnet50
  Neck: bnneck
  Neck Feat: after
============================================================
모델 파일 로드 중: log/gu/reid_baseline_review/Opensource_test/market1501/Experiment-all-tricks-256x128-bs16x4-warmup10-erase0_5-labelsmooth_on-laststride1-bnneck_on/resnet50_model_120.pth
Traceback (most recent call last):
  File "/home/jongphago/projects/reid-strong-baseline/tools/convert_to_onnx.py", line 148, in <module>
    main()
  File "/home/jongphago/projects/reid-strong-baseline/tools/convert_to_onnx.py", line 137, in main
    convert_to_onnx(
  File "/home/jongphago/projects/reid-strong-baseline/tools/convert_to_onnx.py", line 35, in convert_to_onnx
    for key in state_dict.keys():
  File "/home/jongphago/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1269, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'Baseline' object has no attribute 'keys'

```

---

<think><details><summary>Thought Process</summary>두 가지 문제가 있습니다:
1. NumPy 버전 호환성 문제 - 경고지만 일단 무시해도 될 것 같습니다
2. torch.load()가 state_dict가 아닌 모델 객체 자체를 반환하는 것 같습니다

모델 파일의 내용을 확인하고 수정해야 합니다. torch.load()가 모델을 반환하는지 state_dict를 반환하는지 확인하기 위해 스크립트를 수정하겠습니다.</details></think>

---

NumPy 호환성 문제와 모델 로드 방식에 문제가 있습니다. 스크립트를 수정하겠습니다.

---

Tool use: **search_replace**


<details><summary>Edit file: /home/jongphago/projects/reid-strong-baseline/tools/convert_to_onnx.py</summary>

**Chunk 1**
Lines added: 8, lines removed: 1

```diff
@@ -28,5 +28,12 @@
      # 모델 파일 로드하여 클래스 수 추정
      print(f"모델 파일 로드 중: {model_path}")
-     state_dict = torch.load(model_path, map_location='cpu')
+     checkpoint = torch.load(model_path, map_location='cpu')
+     
+     # checkpoint가 state_dict인지 확인
+     if isinstance(checkpoint, dict):
+         state_dict = checkpoint
+     else:
+         # 모델 객체인 경우
+         state_dict = checkpoint.state_dict()
      
      # classifier의 weight shape에서 클래스 수 추정
```

</details>

---

<think><details><summary>Thought Process</summary>이제 다시 실행해 봅시다.</details></think>

---

Tool use: **run_terminal_cmd**

```bash
cd /home/jongphago/projects/reid-strong-baseline && python3 tools/convert_to_onnx.py --config_file configs/softmax_triplet.yml --model_path log/gu/reid_baseline_review/Opensource_test/market1501/Experiment-all-tricks-256x128-bs16x4-warmup10-erase0_5-labelsmooth_on-laststride1-bnneck_on/resnet50_model_120.pth --output_path export/resnet50_model_120.onnx
```

```

A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.6 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/jongphago/projects/reid-strong-baseline/tools/convert_to_onnx.py", line 155, in <module>
    main()
  File "/home/jongphago/projects/reid-strong-baseline/tools/convert_to_onnx.py", line 144, in main
    convert_to_onnx(
  File "/home/jongphago/projects/reid-strong-baseline/tools/convert_to_onnx.py", line 30, in convert_to_onnx
    checkpoint = torch.load(model_path, map_location='cpu')
  File "/home/jongphago/.local/lib/python3.10/site-packages/torch/serialization.py", line 789, in load
    return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
  File "/home/jongphago/.local/lib/python3.10/site-packages/torch/serialization.py", line 1131, in _load
    result = unpickler.load()
  File "/home/jongphago/.local/lib/python3.10/site-packages/torch/_utils.py", line 153, in _rebuild_tensor_v2
    tensor = _rebuild_tensor(storage, storage_offset, size, stride)
  File "/home/jongphago/.local/lib/python3.10/site-packages/torch/_utils.py", line 146, in _rebuild_tensor
    t = torch.tensor([], dtype=storage.dtype, device=storage.untyped().device)
/home/jongphago/.local/lib/python3.10/site-packages/torch/_utils.py:146: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:77.)
  t = torch.tensor([], dtype=storage.dtype, device=storage.untyped().device)
============================================================
ONNX 변환 설정:
  설정 파일: configs/softmax_triplet.yml
  모델 파일: log/gu/reid_baseline_review/Opensource_test/market1501/Experiment-all-tricks-256x128-bs16x4-warmup10-erase0_5-labelsmooth_on-laststride1-bnneck_on/resnet50_model_120.pth
  출력 경로: export/resnet50_model_120.onnx
  입력 크기: [256, 128]
  모델 이름: resnet50
  Neck: bnneck
  Neck Feat: after
============================================================
모델 파일 로드 중: log/gu/reid_baseline_review/Opensource_test/market1501/Experiment-all-tricks-256x128-bs16x4-warmup10-erase0_5-labelsmooth_on-laststride1-bnneck_on/resnet50_model_120.pth
감지된 클래스 수: 751
모델 구조 생성 중...
Loading pretrained ImageNet model......
입력 크기: torch.Size([1, 3, 256, 128])
ONNX 변환 시작...
✓ ONNX 변환 완료: export/resnet50_model_120.onnx
파일 크기: 89.63 MB

변환이 성공적으로 완료되었습니다!

```

---

<think><details><summary>Thought Process</summary>성공했습니다! ONNX 변환이 완료되었습니다. NumPy 경고는 있지만 변환 자체는 성공적으로 완료되었습니다.

결과 확인:
- 클래스 수: 751개 (Market1501 데이터셋)
- 입력 크기: [1, 3, 256, 128] (batch_size, channels, height, width)
- 출력 파일: export/resnet50_model_120.onnx
- 파일 크기: 89.63 MB

이제 변환된 파일을 확인하고 사용자에게 보고하겠습니다.</details></think>

---

완료되었습니다! 이제 변환된 파일을 확인하겠습니다.

---

Tool use: **run_terminal_cmd**

```bash
cd /home/jongphago/projects/reid-strong-baseline && ls -lh export/
```

```
total 90M
-rw-rw-r-- 1 jongphago jongphago 90M Oct 13 05:46 resnet50_model_120.onnx

```

---

<think><details><summary>Thought Process</summary>완벽합니다! 변환이 성공적으로 완료되었습니다. 이제 사용자에게 결과를 보고하겠습니다.</details></think>

---

완료되었습니다! 학습된 모델이 성공적으로 ONNX 형식으로 변환되었습니다.

## 변환 결과

### 생성된 파일
- **경로**: `/home/jongphago/projects/reid-strong-baseline/export/resnet50_model_120.onnx`
- **파일 크기**: 90 MB
- **클래스 수**: 751개 (Market1501 데이터셋)

### 변환 스크립트
- **경로**: `/home/jongphago/projects/reid-strong-baseline/tools/convert_to_onnx.py`

### ONNX 모델 정보
- **입력**:
  - 이름: `input`
  - 크기: `[batch_size, 3, 256, 128]` (동적 배치 크기 지원)
  - 형식: RGB 이미지 (channels, height, width)
  
- **출력**:
  - 이름: `output`
  - 크기: `[batch_size, 2048]` (BNNeck 이후의 feature vector)

- **ONNX 버전**: opset 11

### 참고사항
- NumPy 호환성 경고가 있었지만 변환은 정상적으로 완료되었습니다.
- 이 ONNX 모델은 동적 배치 크기를 지원하므로 추론 시 임의의 배치 크기로 사용 가능합니다.
- 추후 다른 에폭의 모델도 변환하려면 동일한 스크립트를 사용하시면 됩니다.

변환 스크립트는 재사용 가능하도록 작성되었으며, 다른 모델 파일도 동일한 방식으로 변환할 수 있습니다.

---

